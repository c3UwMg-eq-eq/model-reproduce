{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:04.962818Z",
     "start_time": "2025-09-20T17:43:04.958815Z"
    }
   },
   "source": [
    "from functools import lru_cache\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pandas import Series\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:04.978550Z",
     "start_time": "2025-09-20T17:43:04.966815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\""
   ],
   "id": "835d1c73ccc8c24a",
   "outputs": [],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:04.987113Z",
     "start_time": "2025-09-20T17:43:04.981548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, nhead, pdrop):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.nhead = nhead\n",
    "\n",
    "        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n",
    "        self.c_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.drop = nn.Dropout(pdrop)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        _, t, _ = x.shape\n",
    "\n",
    "        qkv = self.qkv(x).chunk(3, dim=-1)\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda tsn: rearrange(tsn, 'b t (nh hd) -> b nh t hd', nh=self.nhead), qkv\n",
    "        )\n",
    "\n",
    "        wei = q @ k.transpose(-1, -2) * k.size(dim=-1) ** -0.5\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.to(x.device)\n",
    "            wei = wei.masked_fill(attn_mask[:t, :t] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "        attn = wei @ v\n",
    "        attn = rearrange(attn, 'b nh t hd -> b t (nh hd)')\n",
    "\n",
    "        return self.drop(self.c_proj(attn))"
   ],
   "id": "1d444c32dbb966",
   "outputs": [],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:04.997681Z",
     "start_time": "2025-09-20T17:43:04.991101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, embed_dim, pdrop):\n",
    "        super(FFN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "            nn.Dropout(pdrop),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,\n",
    "                 # Common\n",
    "                 embed_dim,\n",
    "                 # MHA\n",
    "                 nhead,\n",
    "                 attn_pdrop,\n",
    "                 # FFN\n",
    "                 ffn_pdrop\n",
    "                 ):\n",
    "        super(Block, self).__init__()\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = MultiHeadAttention(embed_dim, nhead, attn_pdrop)\n",
    "        self.ffn = FFN(embed_dim, ffn_pdrop)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = x + self.attn(self.ln1(x), attn_mask=attn_mask)\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "        return x"
   ],
   "id": "dbe74fa6da45203f",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:05.008782Z",
     "start_time": "2025-09-20T17:43:05.000674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerLanguageModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 # LM\n",
    "                 vocab_size,\n",
    "                 ctx_len,\n",
    "                 # Common\n",
    "                 embed_dim,\n",
    "                 # Block\n",
    "                 nlayer,\n",
    "                 nhead,\n",
    "                 attn_mask=None,\n",
    "                 attn_pdrop=0.2,\n",
    "                 ffn_pdrop=0.2,\n",
    "                 # Output\n",
    "                 output_dim: int=None\n",
    "                 ):\n",
    "        super(TransformerLanguageModel, self).__init__()\n",
    "        # Properties\n",
    "        self.ctx_len = ctx_len\n",
    "        if attn_mask is None:\n",
    "            attn_mask = torch.tril(torch.ones(ctx_len, ctx_len))\n",
    "        self.attn_mask = attn_mask\n",
    "        self.understanding = output_dim is not None\n",
    "\n",
    "        # Comps\n",
    "        self.tok_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = nn.Embedding(ctx_len, embed_dim)\n",
    "\n",
    "        self.ln_pre = nn.LayerNorm(embed_dim)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(embed_dim, nhead, attn_pdrop, ffn_pdrop) for _ in range(nlayer)]\n",
    "        )\n",
    "        self.ln_post = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.lm_head = nn.Linear(embed_dim, vocab_size if output_dim is None else output_dim)\n",
    "\n",
    "    def generate(self, idx, attn_mask=None, max_new_tokens=100, temp=1.0, topk=None):\n",
    "        if self.understanding:\n",
    "            raise NotImplementedError('Not for generating')\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -self.ctx_len:]\n",
    "            logits = self(idx_cond, attn_mask)\n",
    "            logits_of_last_tick = logits[:, -1, :] / temp\n",
    "            if topk is not None:\n",
    "                vals, _ = torch.topk(logits_of_last_tick, topk)\n",
    "                logits_of_last_tick[logits_of_last_tick < vals[-1]] = float('-inf')\n",
    "            if temp == 0:\n",
    "                idx_next = torch.argmax(logits_of_last_tick, dim=-1, keepdim=True)\n",
    "            else:\n",
    "                probs = logits_of_last_tick.softmax(dim=-1)\n",
    "                idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1) # concat on 'time' dimension\n",
    "        return idx\n",
    "\n",
    "    def forward(self, idx, attn_mask=None):\n",
    "        attn_mask = attn_mask if attn_mask is not None else self.attn_mask\n",
    "\n",
    "        _, t = idx.shape\n",
    "\n",
    "        tok_emb = self.tok_emb(idx)\n",
    "        pos_emb = self.pos_emb(\n",
    "            torch.arange(0, t, dtype=torch.long, device=idx.device)\n",
    "        )\n",
    "\n",
    "        x = tok_emb + pos_emb\n",
    "\n",
    "        x = self.ln_pre(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask=attn_mask)\n",
    "        x = self.ln_post(x)\n",
    "\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if self.understanding:\n",
    "            logits = logits[torch.arange(logits.shape[0]), idx.argmax(dim=-1)]\n",
    "\n",
    "        return logits"
   ],
   "id": "b70d11f8eff20f05",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:05.019261Z",
     "start_time": "2025-09-20T17:43:05.011701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pair(sz: Union[int, tuple]):\n",
    "    if isinstance(sz, int):\n",
    "        return sz, sz\n",
    "    else:\n",
    "        return sz\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 # Vision\n",
    "                 img_size: Union[int, tuple],\n",
    "                 patch_num: Union[int, tuple],\n",
    "                 use_cls_tok: bool,\n",
    "                 # Transformer\n",
    "                 nlayer: int,\n",
    "                 embed_dim: int,\n",
    "                 nhead: int,\n",
    "                 attn_pdrop: float,\n",
    "                 ffn_pdrop: float,\n",
    "                 # Output\n",
    "                 num_classes: int\n",
    "                 ):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        # Properties\n",
    "        img_height, img_width = pair(img_size)\n",
    "        patch_height_n, patch_width_n = pair(patch_num)\n",
    "        scale = embed_dim ** -0.5\n",
    "\n",
    "        self.patch_height, self.patch_width = img_height // patch_height_n, img_width // patch_width_n\n",
    "        self.use_cls_tok = use_cls_tok\n",
    "\n",
    "        # Comps\n",
    "        self.to_patch = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=embed_dim,\n",
    "            kernel_size=(patch_height_n, patch_width_n),\n",
    "            stride=(patch_height_n, patch_width_n),\n",
    "        )\n",
    "\n",
    "        self.pos_emb = nn.Parameter(scale * torch.randn(1, self.patch_height * self.patch_width + 1, embed_dim))\n",
    "        self.cls_emb = nn.Parameter(scale *  torch.randn(embed_dim))\n",
    "\n",
    "        self.ln_pre = nn.LayerNorm(embed_dim)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(embed_dim, nhead, attn_pdrop, ffn_pdrop) for _ in range(nlayer)]\n",
    "        )\n",
    "        self.ln_post = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.proj = nn.Parameter(scale * torch.randn(embed_dim, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.to_patch(x)\n",
    "\n",
    "        idx = rearrange(\n",
    "            patches, 'b c (ph h) (pw w) -> b (ph pw) (c h w)', ph=self.patch_height, pw=self.patch_width\n",
    "        )\n",
    "\n",
    "\n",
    "        idx = torch.cat(\n",
    "            (\n",
    "                idx,\n",
    "                repeat(self.cls_emb, 'e -> b 1 e', b=idx.shape[0])\n",
    "            ), dim=1\n",
    "        )\n",
    "        x = idx + self.pos_emb\n",
    "\n",
    "\n",
    "        x = self.ln_pre(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        if self.use_cls_tok:\n",
    "            x = x[:, 0, :]\n",
    "        else:\n",
    "            x = x[:, 1:, :].mean(dim=1)\n",
    "\n",
    "        x = self.ln_post(x)\n",
    "\n",
    "        return x @ self.proj"
   ],
   "id": "af41ab8dcba651a3",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:05.028111Z",
     "start_time": "2025-09-20T17:43:05.022265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CLIP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_encoder,\n",
    "                 text_encoder,\n",
    "                 ):\n",
    "        super(CLIP, self).__init__()\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "\n",
    "        self.img_encoder = img_encoder\n",
    "        self.text_encoder = text_encoder\n",
    "\n",
    "    def encode_img(self, img):\n",
    "        return self.img_encoder(img)\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        return self.text_encoder(text)\n",
    "\n",
    "    def forward(self, imgs, texts):\n",
    "        img_features = self.encode_img(imgs)\n",
    "        text_features = self.encode_text(texts)\n",
    "\n",
    "        if img_features.shape != text_features.shape:\n",
    "            raise ValueError(f'img_features shape {img_features.shape} != text_features shape {text_features.shape}')\n",
    "\n",
    "        img_features = img_features / img_features.norm(dim=1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=1, keepdim=True)\n",
    "\n",
    "        logits_per_img = img_features @ text_features.t() * self.logit_scale.exp()\n",
    "        logits_per_text = logits_per_img.t()\n",
    "\n",
    "        return logits_per_img, logits_per_text"
   ],
   "id": "30c2205b0d61c16c",
   "outputs": [],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:06.089214Z",
     "start_time": "2025-09-20T17:43:05.032095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ctx = Series()\n",
    "\n",
    "ctx.train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomErasing(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "ctx.test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "train_cifar10_ds = datasets.CIFAR10(root='~/data', train=True, transform=ctx.train_transform)\n",
    "test_cifar10_ds = datasets.CIFAR10(root='~/data', train=True, transform=ctx.test_transform)"
   ],
   "id": "887cb5b95a660b50",
   "outputs": [],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:07.443983Z",
     "start_time": "2025-09-20T17:43:06.181200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ctx.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ctx.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "ctx.tokenizer.pad_token = ctx.tokenizer.eos_token\n",
    "ctx.label2cls_dict = train_cifar10_ds.classes\n",
    "ctx.ctx_len = 5\n",
    "ctx.batch_size = 256\n",
    "\n",
    "def label2sentence(label, prefix='The photo of a '):\n",
    "    return prefix + ctx.label2cls_dict[label]\n",
    "\n",
    "def tokenize(s):\n",
    "    return ctx.tokenizer(\n",
    "        s,\n",
    "        max_length=ctx.ctx_len,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "    )['input_ids'].squeeze(dim=0)"
   ],
   "id": "c2e329d952161dfc",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T17:43:07.645631Z",
     "start_time": "2025-09-20T17:43:07.514695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextImgDataset(Dataset):\n",
    "    def __init__(self, img_label_ds):\n",
    "        self.img_label_ds = img_label_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_label_ds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        orig_img, orig_label = self.img_label_ds[index]\n",
    "        sentence = label2sentence(orig_label)\n",
    "        return orig_img, tokenize(sentence)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    TextImgDataset(train_cifar10_ds),\n",
    "    batch_size=ctx.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    TextImgDataset(test_cifar10_ds),\n",
    "    batch_size=ctx.batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "for imgs, texts in train_dl:\n",
    "    print(imgs.shape, texts.shape)\n",
    "    break"
   ],
   "id": "84cbdfb6346986fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 5])\n"
     ]
    }
   ],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T18:18:50.580743Z",
     "start_time": "2025-09-20T17:43:07.651630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clip_loss(logits_per_image, logits_per_text):\n",
    "    b = logits_per_text.shape[0]\n",
    "    labels = torch.arange(0, b, device=logits_per_text.device)\n",
    "    image_loss = F.cross_entropy(logits_per_image, labels)\n",
    "    text_loss = F.cross_entropy(logits_per_text, labels)\n",
    "    return (image_loss + text_loss) / 2\n",
    "\n",
    "ctx.epochs = 50\n",
    "ctx.lr = 1e-4\n",
    "ctx.weight_decay = 1e-5\n",
    "ctx.eval_interval = 3\n",
    "ctx.saved_w = 'clip.pt'\n",
    "\n",
    "model = CLIP(\n",
    "    img_encoder=VisionTransformer(\n",
    "        img_size=32,\n",
    "        patch_num=8,\n",
    "        use_cls_tok=False,\n",
    "        nlayer=4,\n",
    "        embed_dim=768,\n",
    "        nhead=12,\n",
    "        attn_pdrop=0.2,\n",
    "        ffn_pdrop=0.2,\n",
    "        num_classes=128,\n",
    "    ),\n",
    "    text_encoder=TransformerLanguageModel(\n",
    "        vocab_size=ctx.tokenizer.vocab_size,\n",
    "        ctx_len=ctx.ctx_len,\n",
    "        embed_dim=768,\n",
    "        nlayer=4,\n",
    "        nhead=12,\n",
    "        attn_mask=None, # Default: Casual Attention Mask\n",
    "        attn_pdrop=0.2,\n",
    "        ffn_pdrop=0.2,\n",
    "        output_dim=128\n",
    "    )\n",
    ").to(ctx.device)\n",
    "\n",
    "if os.path.isfile(ctx.saved_w):\n",
    "    model.load_state_dict(torch.load(ctx.saved_w, weights_only=True))\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=ctx.lr,\n",
    "    weight_decay=ctx.weight_decay,\n",
    ")\n",
    "\n",
    "@lru_cache\n",
    "def tokenized_sentences():\n",
    "    labels = range(len(ctx.label2cls_dict))\n",
    "    return torch.stack([tokenize(label2sentence(label)) for label in labels])\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_accuracy():\n",
    "    def eq_cnt(l1, l2):\n",
    "        n = len(l1)\n",
    "        cnt = 0\n",
    "        for i in range(n):\n",
    "            if l1[i] == l2[i]:\n",
    "                cnt += 1\n",
    "        return cnt\n",
    "    model.eval()\n",
    "    text_features = model.encode_text(\n",
    "        tokenized_sentences().to(ctx.device)\n",
    "    )\n",
    "    text_features = text_features / text_features.norm(dim=1, keepdim=True)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    pbar = tqdm(test_dl)\n",
    "    pbar.set_description_str('Evaling accuracy on test set')\n",
    "    for imgs, texts in pbar:\n",
    "        imgs = imgs.to(ctx.device)\n",
    "        texts = texts.to(ctx.device)\n",
    "        image_features = model.encode_img(imgs)\n",
    "        logits_per_image = image_features @ text_features.t()\n",
    "        labels = logits_per_image.argmax(dim=1)\n",
    "        pred = [label2sentence(label) for label in labels]\n",
    "        gt = [ctx.tokenizer.decode(text, skipskip_special_tokens=True) for text in texts]\n",
    "        total += len(imgs)\n",
    "        correct += eq_cnt(pred, gt)\n",
    "    return correct / total\n",
    "\n",
    "len_train_dl = len(train_dl)\n",
    "for epoch in range(1, ctx.epochs + 1):\n",
    "    train_avg_loss = 0.\n",
    "    pbar = tqdm(train_dl)\n",
    "    pbar.set_description_str(f'Training one epoch {epoch}/{ctx.epochs}')\n",
    "    for imgs, texts in pbar:\n",
    "        imgs = imgs.to(ctx.device)\n",
    "        texts = texts.to(ctx.device)\n",
    "        optimizer.zero_grad()\n",
    "        logits_per_image, logits_per_text = model(imgs, texts)\n",
    "        loss = clip_loss(logits_per_image, logits_per_text)\n",
    "        train_avg_loss += loss.item() / len_train_dl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % ctx.eval_interval == 0:\n",
    "        print(f'{epoch}/{ctx.epochs}, train_avg_loss: {train_avg_loss:.3f}, test_acc: {eval_accuracy()}')\n",
    "    else:\n",
    "        print(f'{epoch}/{ctx.epochs}, train_avg_loss: {train_avg_loss:.3f}')"
   ],
   "id": "ea01f52e7cd80378",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 1/50: 100%|██████████| 196/196 [00:36<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/50, train_avg_loss: 5.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 2/50: 100%|██████████| 196/196 [00:36<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/50, train_avg_loss: 5.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 3/50: 100%|██████████| 196/196 [00:35<00:00,  5.47it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:22<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/50, train_avg_loss: 5.016, test_acc: 0.39684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 4/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/50, train_avg_loss: 4.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 5/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/50, train_avg_loss: 4.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 6/50: 100%|██████████| 196/196 [00:38<00:00,  5.09it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:24<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/50, train_avg_loss: 4.762, test_acc: 0.48972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 7/50: 100%|██████████| 196/196 [00:37<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/50, train_avg_loss: 4.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 8/50: 100%|██████████| 196/196 [00:37<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/50, train_avg_loss: 4.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 9/50: 100%|██████████| 196/196 [00:35<00:00,  5.45it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:22<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/50, train_avg_loss: 4.616, test_acc: 0.52602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 10/50: 100%|██████████| 196/196 [00:35<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/50, train_avg_loss: 4.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 11/50: 100%|██████████| 196/196 [00:35<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/50, train_avg_loss: 4.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 12/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:22<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/50, train_avg_loss: 4.519, test_acc: 0.55914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 13/50: 100%|██████████| 196/196 [00:35<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/50, train_avg_loss: 4.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 14/50: 100%|██████████| 196/196 [00:35<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/50, train_avg_loss: 4.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 15/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/50, train_avg_loss: 4.438, test_acc: 0.58668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 16/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/50, train_avg_loss: 4.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 17/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/50, train_avg_loss: 4.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 18/50: 100%|██████████| 196/196 [00:35<00:00,  5.50it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:22<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/50, train_avg_loss: 4.375, test_acc: 0.60834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 19/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/50, train_avg_loss: 4.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 20/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/50, train_avg_loss: 4.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 21/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/50, train_avg_loss: 4.320, test_acc: 0.62612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 22/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/50, train_avg_loss: 4.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 23/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/50, train_avg_loss: 4.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 24/50: 100%|██████████| 196/196 [00:35<00:00,  5.50it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/50, train_avg_loss: 4.275, test_acc: 0.64294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 25/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/50, train_avg_loss: 4.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 26/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/50, train_avg_loss: 4.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 27/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/50, train_avg_loss: 4.231, test_acc: 0.6546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 28/50: 100%|██████████| 196/196 [00:35<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/50, train_avg_loss: 4.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 29/50: 100%|██████████| 196/196 [00:35<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/50, train_avg_loss: 4.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 30/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/50, train_avg_loss: 4.193, test_acc: 0.6665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 31/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/50, train_avg_loss: 4.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 32/50: 100%|██████████| 196/196 [00:35<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/50, train_avg_loss: 4.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 33/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/50, train_avg_loss: 4.158, test_acc: 0.67598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 34/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/50, train_avg_loss: 4.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 35/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/50, train_avg_loss: 4.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 36/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/50, train_avg_loss: 4.128, test_acc: 0.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 37/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/50, train_avg_loss: 4.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 38/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/50, train_avg_loss: 4.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 39/50: 100%|██████████| 196/196 [00:35<00:00,  5.50it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/50, train_avg_loss: 4.100, test_acc: 0.69454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 40/50: 100%|██████████| 196/196 [00:35<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/50, train_avg_loss: 4.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 41/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/50, train_avg_loss: 4.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 42/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/50, train_avg_loss: 4.080, test_acc: 0.69682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 43/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/50, train_avg_loss: 4.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 44/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/50, train_avg_loss: 4.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 45/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/50, train_avg_loss: 4.053, test_acc: 0.70694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 46/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/50, train_avg_loss: 4.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 47/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/50, train_avg_loss: 4.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 48/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]\n",
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:21<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/50, train_avg_loss: 4.027, test_acc: 0.71234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 49/50: 100%|██████████| 196/196 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/50, train_avg_loss: 4.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training one epoch 50/50: 100%|██████████| 196/196 [00:35<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50, train_avg_loss: 4.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T18:20:31.435593Z",
     "start_time": "2025-09-20T18:20:08.392928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(), ctx.saved_w\n",
    ")\n",
    "\n",
    "eval_accuracy()"
   ],
   "id": "6f6ba6cd7566d404",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaling accuracy on test set: 100%|██████████| 196/196 [00:22<00:00,  8.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71722"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 233
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
